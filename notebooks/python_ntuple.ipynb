{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "from collections import Counter\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def get_types_in_block(X, y, blk):\n",
    "    return [int(x) for x in sorted(X[y==blk, 0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Load all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_sgs = []\n",
    "\n",
    "num_clusters = []\n",
    "num_tracks = []\n",
    "num_cands = []\n",
    "num_blocks = []\n",
    "\n",
    "for fi in glob.glob(\"../data/TTbar/*ev*.npz\")[:500]:\n",
    "    fi = open(fi, \"rb\")\n",
    "    data = np.load(fi)\n",
    "    \n",
    "    #list of PF input elements in the event\n",
    "    X = data[\"elements\"]\n",
    "    \n",
    "    #tracks have type=1\n",
    "    num_clusters += [np.sum(X[:, 0] != 1)]\n",
    "    num_tracks += [np.sum(X[:, 0] == 1)]\n",
    "    \n",
    "    #unique ID for each cluster/block of elements that the PFAlgo considered independently\n",
    "    #this can be considered as the target output of an improved PFBlockAlgo\n",
    "    y = data[\"element_block_id\"]\n",
    "    num_blocks += [len(np.unique(y))]\n",
    "\n",
    "    #List of candidates produced in the event.\n",
    "    #This can be considered as the output of PFAlgo\n",
    "    cands = data[\"candidates\"]\n",
    "    num_cands += [len(cands)]\n",
    "\n",
    "    #get the types of the elements for each cluster/block\n",
    "    sgs = [tuple(get_types_in_block(X, y, blk)) for blk in np.unique(y)]\n",
    "    all_sgs += sgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(num_clusters, bins=np.linspace(0,5000,100), label=\"clusters\", alpha=0.5);\n",
    "plt.hist(num_tracks, bins=np.linspace(0,5000,100), label=\"tracks\", alpha=0.5);\n",
    "plt.legend()\n",
    "plt.xlabel(\"number of elements\")\n",
    "plt.ylabel(\"number of events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(num_cands, bins=np.linspace(0,4000,100));\n",
    "plt.xlabel(\"number of candidates\")\n",
    "plt.ylabel(\"number of events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(num_blocks, bins=np.linspace(0,4000,100));\n",
    "plt.xlabel(\"number of miniblocks\")\n",
    "plt.ylabel(\"number of events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the number of blocks of a certain size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "block_sizes = Counter([len(sg) for sg in all_sgs])\n",
    "print(\"block sizes\", block_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist([len(sg) for sg in all_sgs], bins=np.linspace(0,100,101));\n",
    "plt.xlabel(\"block size\")\n",
    "plt.ylabel(\"Number of blocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist([len(sg) for sg in all_sgs], bins=np.linspace(0,100,101));\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"block size\")\n",
    "plt.ylabel(\"number of blocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what the blocks f size, 1, 2, 3 and 4 are made of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_block_nelem(blocks_nelem):\n",
    "    kv = list(blocks_nelem.items())\n",
    "    xs = np.arange(len(kv))\n",
    "    ys = np.array([v for k, v in kv])\n",
    "\n",
    "    plt.bar(xs, ys)\n",
    "    plt.xticks(xs, [k for k, v in kv], rotation=90)\n",
    "    \n",
    "\n",
    "for blocksize in range(1,5):\n",
    "    sizes = [\",\".join(map(str, sg)) for sg in all_sgs if len(sg)==blocksize]\n",
    "    blocks_nelem = Counter(sizes)\n",
    "    print(\"{0}-element blocks\".format(blocksize), blocks_nelem)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.title(\"Blocks of size {0}: {1} ({2:.0f}%)\".format(blocksize, len(sizes), 100.0*len(sizes)/len(all_sgs)))\n",
    "    plot_block_nelem(blocks_nelem)\n",
    "    plt.xlabel(\"Block element types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 10 blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "block_ids = data[\"element_block_id\"]\n",
    "inds_elem = np.arange(len(X))\n",
    "inds_cand = np.arange(len(cands))\n",
    "for blk in np.unique(block_ids)[:20]:\n",
    "    candidates_from_block = data[\"candidate_block_id\"] == blk\n",
    "    elems_in_block = y == blk\n",
    "    \n",
    "    print(\"in block\", blk, \"had the following elements: {0}\".format(get_types_in_block(X, y, blk)))\n",
    "    for ielem in inds_elem[elems_in_block]:\n",
    "        print(\"  elements[{0}]: type={1} energy={2:.2f}\".format(ielem, int(X[ielem, 0]), X[ielem, 1]))\n",
    "    print(\"from which the following candidates were produced\")\n",
    "    for icand in inds_cand[candidates_from_block]:\n",
    "        print(\"  candidates[{0}]: pdgid={1} pt={2:.2f}\".format(icand, int(cands[icand, 0]), cands[icand, 1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_X_y(X, Xbl, y, ybl, blsize=3, maxn=3):\n",
    "    uniqs = np.unique(Xbl)\n",
    "\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    for bl in uniqs:\n",
    "        subX = X[Xbl==bl]\n",
    "        suby = y[ybl==bl][:maxn]\n",
    "        \n",
    "        #choose only miniblocks with 3 elements to simplify the problem\n",
    "        if subX.shape[0] > blsize:\n",
    "            continue\n",
    "\n",
    "        subX = np.pad(subX, ((0, blsize - subX.shape[0]), (0,0)), mode=\"constant\")\n",
    "        suby = np.pad(suby, ((0, maxn - suby.shape[0]), (0,0)), mode=\"constant\")\n",
    "\n",
    "        Xs += [subX]\n",
    "        ys += [suby]\n",
    "\n",
    "    return Xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Xs = []\n",
    "all_ys = []\n",
    "\n",
    "for fi in glob.glob(\"../data/TTbar/*ev*.npz\")[:500]:\n",
    "    fi = open(fi, \"rb\")\n",
    "    data = np.load(fi)\n",
    "    \n",
    "    Xs, ys = get_unique_X_y(data[\"elements\"], data[\"element_block_id\"], data[\"candidates\"], data[\"candidate_block_id\"])\n",
    "\n",
    "    all_Xs += [Xs]\n",
    "    all_ys += [ys]\n",
    "    \n",
    "all_Xs = np.vstack(all_Xs)\n",
    "all_ys = np.vstack(all_ys)\n",
    "\n",
    "shuf = np.random.permutation(range(len(all_Xs)))\n",
    "all_Xs = all_Xs[shuf]\n",
    "all_ys = all_ys[shuf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Xs_types = all_Xs[:, :, 0]\n",
    "all_Xs_kin = all_Xs[:, :, 1:]\n",
    "\n",
    "all_ys_types = all_ys[:, :, 0]\n",
    "all_ys_kin = all_ys[:, :, 1:]\n",
    "\n",
    "all_Xs_kin = np.copy(all_Xs_kin.reshape(all_Xs_kin.shape[0], all_Xs_kin.shape[1]*all_Xs_kin.shape[2]))\n",
    "all_ys_kin = np.copy(all_ys_kin.reshape(all_ys_kin.shape[0], all_ys_kin.shape[1]*all_ys_kin.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = sklearn.preprocessing.StandardScaler().fit(all_Xs_kin)\n",
    "scaler_y = sklearn.preprocessing.StandardScaler().fit(all_ys_kin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_X = sklearn.preprocessing.OneHotEncoder(categories=\"auto\", sparse=False)\n",
    "enc_y = sklearn.preprocessing.OneHotEncoder(categories=\"auto\", sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_X.fit(all_Xs_types)\n",
    "trf = enc_X.transform(all_Xs_types)\n",
    "X = np.hstack([trf, scaler_X.transform(all_Xs_kin)])\n",
    "\n",
    "enc_y.fit(all_ys_types)\n",
    "trf = enc_y.transform(all_ys_types)\n",
    "y = np.hstack([trf, scaler_y.transform(all_ys_kin)])\n",
    "\n",
    "num_onehot_y = trf.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "nunit = 512\n",
    "dropout = 0.2\n",
    "\n",
    "model.add(keras.layers.Dense(nunit, input_shape=(X.shape[1], )))\n",
    "\n",
    "model.add(keras.layers.advanced_activations.LeakyReLU())\n",
    "model.add(keras.layers.Dropout(dropout))\n",
    "model.add(keras.layers.Dense(nunit))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.advanced_activations.LeakyReLU())\n",
    "model.add(keras.layers.Dropout(dropout))\n",
    "model.add(keras.layers.Dense(nunit))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.advanced_activations.LeakyReLU())\n",
    "model.add(keras.layers.Dropout(dropout))\n",
    "model.add(keras.layers.Dense(nunit))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.advanced_activations.LeakyReLU())\n",
    "model.add(keras.layers.Dropout(dropout))\n",
    "model.add(keras.layers.Dense(nunit))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.advanced_activations.LeakyReLU())\n",
    "model.add(keras.layers.Dense(y.shape[1]))\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=1e-3)\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=opt)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[4, :], y[4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ntrain = int(0.8*len(all_Xs))\n",
    "ret = model.fit(\n",
    "    X[:ntrain], y[:ntrain],\n",
    "    validation_data=(X[ntrain:], y[ntrain:]),\n",
    "    batch_size=1000, epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ret.history[\"loss\"])\n",
    "plt.plot(ret.history[\"val_loss\"])\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = model.predict(X, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_candids = enc_y.inverse_transform(pp[:, :num_onehot_y]>0.5)\n",
    "ncands = np.sum(pp_candids!=0, axis=1)\n",
    "ncands_true = np.sum(all_ys_types!=0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_test = np.zeros(len(X), dtype=np.bool)\n",
    "msk_test[ntrain:] = 1\n",
    "\n",
    "msk_1true = np.zeros(len(X), dtype=np.bool)\n",
    "msk_1true[ncands_true==1] = 1\n",
    "\n",
    "msk_1pred = np.zeros(len(X), dtype=np.bool)\n",
    "msk_1pred[ncands==1] = 1\n",
    "\n",
    "msk_2true = np.zeros(len(X), dtype=np.bool)\n",
    "msk_2true[ncands_true==2] = 1\n",
    "\n",
    "msk_3true = np.zeros(len(X), dtype=np.bool)\n",
    "msk_3true[ncands_true==3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(all_ys_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = all_ys_types[:, 0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter([tuple(sorted(map(int, i))) for i in all_Xs_types[m]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix_ncands = sklearn.metrics.confusion_matrix(ncands_true[msk_test], ncands[msk_test], labels=[0,1,2,3])\n",
    "plt.imshow(cmatrix_ncands, norm=matplotlib.colors.LogNorm())\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"true ncand\")\n",
    "plt.ylabel(\"predicted ncand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(all_ys_types)\n",
    "mat = sklearn.metrics.confusion_matrix(all_ys_types[msk_test & msk_1true, 0], pp_candids[msk_test & msk_1true, 0], labels=labels)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mat, norm=matplotlib.colors.LogNorm())\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"true pdgid\")\n",
    "plt.ylabel(\"predicted pdgid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_transformed = scaler_y.inverse_transform(pp[:, num_onehot_y:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the candidate momentum to 0 for the candidates that were not predicted\n",
    "@numba.njit\n",
    "def postprocess_cand_momentum(pp_transformed, ncands_pred):\n",
    "    for i in range(len(ncands_pred)):\n",
    "        ncands = ncands_pred[i]\n",
    "        d = np.copy(pp_transformed[i, :])\n",
    "        pp_transformed[i, :] = 0\n",
    "        pp_transformed[i, :ncands*3] = d[:ncands*3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_transformed[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess_cand_momentum(pp_transformed, ncands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(all_ys_kin[msk_test&msk_1true&msk_1pred, 0], pp_transformed[msk_test&msk_1true&msk_1pred, 0], marker=\".\")\n",
    "plt.plot([0,10],[0,10], lw=1, color=\"black\")\n",
    "plt.xlim(-1,10)\n",
    "plt.ylim(-1,10)\n",
    "plt.xlabel(\"First PFCandidate pT (true)\")\n",
    "plt.ylabel(\"First PFCandidate pT (predicted)\")\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "bins = np.linspace(0,5,60)\n",
    "plt.hist(all_ys_kin[msk_test & msk_1true&msk_1pred, 0], bins=bins, histtype=\"step\", lw=2);\n",
    "plt.hist(pp_transformed[msk_test & msk_1true&msk_1pred, 0], bins=bins, histtype=\"step\", lw=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "plt.scatter(all_ys_kin[msk_test&msk_1true&msk_1pred, 1], pp_transformed[msk_test&msk_1true&msk_1pred, 1], marker=\".\")\n",
    "plt.plot([-6,6],[-6,6], lw=1, color=\"black\")\n",
    "plt.xlim(-6,6)\n",
    "plt.ylim(-6,6)\n",
    "plt.xlabel(\"First PFCandidate eta (true)\")\n",
    "plt.ylabel(\"First PFCandidate eta (predicted)\")\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "bins = np.linspace(-6,6,60)\n",
    "plt.hist(all_ys_kin[msk_test & msk_1true&msk_1pred, 1], bins=bins, histtype=\"step\", lw=2);\n",
    "plt.hist(pp_transformed[msk_test & msk_1true&msk_1pred, 1], bins=bins, histtype=\"step\", lw=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "plt.scatter(all_ys_kin[msk_test&msk_1true&msk_1pred, 2], pp_transformed[msk_test&msk_1true&msk_1pred, 2], marker=\".\")\n",
    "plt.plot([-4,4],[-4,4], lw=1, color=\"black\")\n",
    "plt.xlim(-4,4)\n",
    "plt.ylim(-4,4)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "bins = np.linspace(-4,4,60)\n",
    "plt.hist(all_ys_kin[msk_test & msk_1true&msk_1pred, 2], bins=bins, histtype=\"step\", lw=2);\n",
    "\n",
    "plt.hist(pp_transformed[msk_test & msk_1true&msk_1pred, 2], bins=bins, histtype=\"step\", lw=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
